{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossRef Local - Demo for the LLM Era\n",
    "\n",
    "Key features that matter for AI research assistants:\n",
    "\n",
    "1. **ABSTRACTS** - Full text for LLM context (not available in many APIs)\n",
    "2. **IMPACT FACTOR** - Journal quality assessment  \n",
    "3. **CITATIONS** - Paper importance metrics\n",
    "4. **SPEED** - 167M records in milliseconds, no rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from crossref_local import search, get, count, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = info()\n",
    "print(f\"Works:     {db['works']:,}\")\n",
    "print(f\"FTS:       {db['fts_indexed']:,}\")\n",
    "print(f\"Citations: {db['citations']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Abstracts - Full Text for LLM Context\n",
    "\n",
    "Unlike many APIs, CrossRef includes abstracts - essential for LLMs to understand paper content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search(\"hippocampal memory consolidation\", limit=3)\n",
    "\n",
    "for work in results.works:\n",
    "    print(f\"üìÑ {work.title}\")\n",
    "    print(f\"   {work.journal} ({work.year})\")\n",
    "    if work.abstract:\n",
    "        print(f\"   üìù {work.abstract[:300]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Impact Factor - Assess Journal Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crossref_local.impact_factor import ImpactFactorCalculator\n",
    "\n",
    "with ImpactFactorCalculator() as calc:\n",
    "    for journal in [\"Nature\", \"Science\", \"Cell\", \"PLOS ONE\"]:\n",
    "        result = calc.calculate_impact_factor(journal, target_year=2023)\n",
    "        if result:\n",
    "            print(f\"{journal}: IF = {result['impact_factor']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Speed - 167M Records, No Rate Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "queries = [\"machine learning\", \"CRISPR\", \"climate change\", \"neural network\"]\n",
    "\n",
    "for q in queries:\n",
    "    start = time.perf_counter()\n",
    "    n = count(q)\n",
    "    elapsed = (time.perf_counter() - start) * 1000\n",
    "    print(f\"{q:<20} ‚Üí {n:>10,} matches in {elapsed:.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Work by DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work = get(\"10.1038/nature12373\")\n",
    "\n",
    "if work:\n",
    "    print(f\"Title:   {work.title}\")\n",
    "    print(f\"Authors: {', '.join(work.authors)}\")\n",
    "    print(f\"Year:    {work.year}\")\n",
    "    print(f\"Journal: {work.journal}\")\n",
    "    print(f\"\\nCitation: {work.citation()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: LLM Research Assistant\n",
    "\n",
    "Build context for an LLM by retrieving relevant papers with abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_research_context(topic: str, n_papers: int = 5) -> str:\n",
    "    \"\"\"Build LLM context from relevant papers.\"\"\"\n",
    "    results = search(topic, limit=n_papers)\n",
    "    \n",
    "    context = f\"## Research Context: {topic}\\n\\n\"\n",
    "    \n",
    "    for i, work in enumerate(results.works, 1):\n",
    "        context += f\"### Paper {i}: {work.title}\\n\"\n",
    "        context += f\"- Authors: {', '.join(work.authors[:3])}\"\n",
    "        if len(work.authors) > 3:\n",
    "            context += \" et al.\"\n",
    "        context += f\"\\n- Journal: {work.journal} ({work.year})\\n\"\n",
    "        if work.abstract:\n",
    "            context += f\"- Abstract: {work.abstract}\\n\"\n",
    "        context += f\"- DOI: {work.doi}\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "# Example\n",
    "context = build_research_context(\"transformer attention mechanism\", n_papers=3)\n",
    "print(context[:2000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TODO: Graphing Support\n",
    "\n",
    "Future features:\n",
    "- Citation network visualization\n",
    "- Impact factor trends over time\n",
    "- Author collaboration networks\n",
    "- Topic clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
